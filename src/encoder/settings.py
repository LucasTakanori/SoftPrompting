TRAIN_DEFAULT_SETTINGS = {
    "utterances_path": "/gpfs/projects/bsc88/speech/research/repos/SoftPrompting/data/train.tsv",
    "random_seed": 1234,
    "max_epochs": 4,
    "load_checkpoint" : False,
    "checkpoint_file_folder": "/gpfs/projects/bsc88/speech/research/repos/SoftPrompting/checkpoints",
    "checkpoint_file_name": "latest_checkpoint.pth",
    "training_augmentation_prob": 0,
    "evaluation_augmentation_prob": 0,
    "sample_rate": 16000,
    "whisper_flavour": "/gpfs/projects/bsc88/speech/research/models/hf_models/whisper-large-v2",
    "batch_size": 10,
    "num_workers": 16,
    "random_crop_secs": 30,
    "padding_type": "zero_pad",
    "asr_model": "whisper",
    "learning_rate": 1e-3,
    "tokens_max_length": 444,
    "prompt_use_rate": 1,
    "prompt_length": 100,
    "speech_representation": "mel",
    "nmels": 80,
    "context_len": 100,
    "loss": "CrossEntropy",
    "optimizer": "adam",
    "vocab_size":51865 ,
    "validation_utterances_path":"/gpfs/projects/bsc88/speech/research/repos/SoftPrompting/data/dev.tsv",
    "eval_and_save_best_model_every": 3229,
    "use_weights_and_biases": True,
    "wandb_project": "SOFT_PROMPTING_ENCODER",
    "wandb_entity": 'bsc',  
    "wandb_run_name": 'Encoder_large-v2',      
    "wandb_mode": "offline",  
}
#"/gpfs/projects/bsc88/speech/research/db/lt/train.tsv
#/gpfs/projects/bsc88/speech/research/repos/SoftPrompting/data/train.tsv